Comparing the performance of peak callers
------------------------------------------

No research on peak callers and their parameters for ATAC data has currently
been done. We decided to test two widely used peak callers -- Macs2 (initially
designed for ChIP-Seq data) and FSeq (initially designed for DNaseI data). We
ran peak calling using each of the tools and ranging two parameters which are
expected to have a major influence on peak calling:

- length/width/shifting of the statistical model which directly influences the
  average width of peaks to be called (`-l` for FSeq; `--extsize` for Macs2)
- significance threshold which determines how different from a background noise
  the signal should be to be considered as a peak (`-t` for FSeq; `--qvalue`
  for Macs2)

We used data generated from fresh K562 cells, as we consider it gold standard,
least biased (by freezing/fixing) and most accurate, therefore a perfect
candidate for testing peak callers on.

#### Experimental design

We had three samples (`bam` files as input for Macs2 and `bed` files as input
for FSeq) of fresh K562 cells, namely `fresh1`, `fresh2`, `fresh3`, which were
technical replicates of the same sample.

We ran
[FSeq](https://raw.githubusercontent.com/jknightlab/ATACseq_pipeline/master/Core_manuscript/Fseq_Macs2_Hotspot/run_fseq.sh)
ranging the two parameters in the following way:


- `-l`: 100 200 400 600 800 1000 2000
- `-t`: 2 4 6 8 10 12 14 16 

We ran
[Macs2](https://raw.githubusercontent.com/jknightlab/ATACseq_pipeline/master/Core_manuscript/Fseq_Macs2_Hotspot/run_macs.sh)
ranging the two parameters in the following way:

- `--extsize`: 10 100 200 400 600 800 1000 2000 
- `--qvalue`: 0.001 0.005 0.01 0.05 0.1 0.5 

Code to generate intersections (using Fseq peaks as example):
```
for l in `echo 100 200 400 600 800 1000 2000`
do
    for t in `echo 2 4 6 8 10 12 14 16`
    do
        fresh1="fresh1.fseq.length_$l.tresh_$t.bed"
        fresh2="fresh2.fseq.length_$l.tresh_$t.bed"
        fresh3="fresh3.fseq.length_$l.tresh_$t.bed"
        bedtools intersect -f 0.3 -r -a $fresh1 -b $fresh2 | \
            bedtools intersect -f 0.3 -r -a - -b $fresh3 | \
            bedtools merge -i - > \
            fresh.fseq.length_$l.tresh_$t.intrsct.bed;
    done
done
```

#### Choice of best parameters per peak caller

Choosing best parameters per peak caller turned out to be very complicated. We
looked at things like sensitivity, specificity, F-Score, distribution of called
peaks across annotated categories (TSS, enhancer regions, repressed regions,
etc). The problem with all those metrics is that when we increase the
width/length parameter, peak callers tend to call wider peaks, often join
narrow adjacent peaks. When we have wider window (2000 bases compared to 100),
we will most probably call more "true" events (annotated peaks), simply because
the covered area is so wide. Therefore we decided to look at a number of
metrics (FDR, sensitivity, specificity, F-Score) and choose the best parameter
set based on the combination of these metrics.

To identify "true annotated peaks", we need a good annotation which contains
only regions that we expect ATAC peaks to map to (such as promoters and
enhancers; but not repressed or transcribed regions). We looked at different
annotations and their combinations:

- Encode K562 regulatory elements annotation generated by Segwey
- Encode K562 regulatory elements annotation generated by ChromM
- Duke K562 DNaseI sites
- overlap of "1_active_promoter", "2_weak_promoter", "4_strong_enhancer",
  "6_weak_enhancer" from ChromM
- overlap of that with DNase
- overlap of "TSS", "Enhancer", "Weak_Enhancer" from Segwey
- overlap of that with DNase
- overlap of "on target" areas (described above) between ChromM and Segwey
- overlap of "on target" areas (described above) between ChromM, Segwey and
  DNase

We came to the conclusion that Segwey "on target" areas are the best annotation
set. Annotation provided by ChromM contains too wide peaks (kbs wide).
Annotation of DNase peaks contains too narrow peaks (150 bp wide). Overlaps of
the annotations produce very limited, restricted lists of regions which do not
tend to be informative.

We used the intersection of peaks called in 3 fresh ATAC K562 samples (peaks
were called intersected if they had at least 30% overlap reciprocally in all
three samples). We required the overlap of 50% of ATAC peak length with an
annotated peak.

[Here](https://raw.githubusercontent.com/jknightlab/ATACseq_pipeline/master/Core_manuscript/Fseq_Macs2_Hotspot/code_for_overlaps.sh)
is the code to generate intersections of peaks and the overlaps of these
intersections with the annotation.



#### Results

FDR (fraction of bases in peaks not called as annotation of all called bases):
data generated by Macs2 for fresh ATAC, frozen ATAC or DNase samples  looks
very similar. Maximum FDR is achieved at higher length parameter, starts
rapidly increasing at the length value of 100-200. We can see that FDR is
always high for low quality threshold (0.99). For FSeq peaks, FDR is always low
for strict quality thresholds (12-16) in fresh samples regardless of the
length. Looking at the data generated by FSeq for frozen ATAC or DNase samples,
we can see that FDR in both of those samples is higher than in fresh samples.
Also, FDR decreases with the increase of threshold. Also, there is a slight
bias trend of shorter lengths~lower FDR in both frozen ATAC and DNase samples.

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/fdr_macs-fseq_fresh-frozen-dnase.png)


Specificity (fraction of bases in peaks called as annotation of all called
bases): for Macs2, specificity is higher for lower length parameters and
stricter quality thresholds. However, the difference in specificity depending
on thresholds is dramatic only when comparing the threshold of 0.99 to any
other thresholds (0.001, 0.01, 0.1 -- not much difference betwee these three).
Peaks called by Fseq have higher specificity with higher quality thresholds and
show a slight bias towards lower length values, but only for  frozen ATAC and
DNase peaks. Observed for both peak callers: the behaviour is very similar for
fresh ATAC, frozen ATAC and DNase data. However, DNase data had lower
specificity than ATAC data for each parameter set.

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/specificity_macs-fseq_fresh-frozen-dnase.png)


Sensitivity (fraction of bases in peaks called as annotation of all annotation
bases): For Macs2, sensitivity reaches its peak around length values of
200-400, being the highest at quality threshold on 0.99. It is shifted towards
smaller length values (10-100) for DNase, which is expected as we suppose that
DNase peaks should be narrower than ATAC peaks and not wider than 150 bp. For
peaks called with FSeq, frozen ATAC and DNase profile of sensitivity look
similar and suggest that higher sensitivity is reached with lower threshold
values. However, the highest sensitivity for fresh ATAC data is reached with
length 800-1000 and threshold value 14-16.

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/sensitivity_macs-fseq_fresh-frozen-dnase.png)


FScore (a combination of sensitivity and specificity with a bit more weight
given to sensitivity): For peaks called with Macs2, the FScore reaches its
maximum around length 100-200 for fresh and frozen ATAC samples and again,
narrower lengths values (10-100) for DNase samples. Similarly to sensitivity,
FSeq data for ATAC fresh samples has a peak at length 800-1000 and threshold
value 14-16.

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/fscore_macs-fseq_fresh-frozen-dnase.png)


FDR/TPR: for both Macs2 and FSeq peaks, for any type of data, higherst
FDR-to-TPR rate is for higher length values and lower quality values. It is
almost equally low for any length valuse below 2000 for FSeq peaks and slightly
lower for low-to-average length values of 100-200 for Macs2.

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/fdr-to-tpr_macs-fseq_fresh-frozen-dnase.png)



**Which parameter set is the best?**

|             | Macs2              | FSeq                |
| ----------- | ------------------ | ------------------- |
| FDR         | lower length value and any threshold value but 0.99 | strict threshold and a slight bias towards lower length values |
| Specificity | lower length value and any quality threshold but 0.99 | strict threshold values and a slight bias towards lower length values |
| Sensitivity | average length values of 100-400 | higher length values (800-1000) and strict thresholds |
| FScore      | average length values of 100-400 | higher length values (800-1000) and strict thresholds |
| FDR/TPR     | average length values of 100-200 and any quality threshold but 0.99 | any length value but 2000 and any threshold value higher than 6 |

Based on the observations described above we chose the following parameters as
optimal:

| Peak caller | Default parameters | Chosen parameters   |
| ----------- | ------------------ | ------------------- |
| FSeq        | l=600, t=4         | **l=800, t=14**     |
| Macs2       | ext=200, q=0.05    | **ext=100, q=0.01** |
















In this figure, left panel represents the performance of FSeq (as heatmap and
as barplot); right panel represents the performance of Macs2 (as heatmap and as
barplot). Heatmap colours range from blue to violet, blue indicating lower
values and violet indicating higher values. Red square on heatmaps highlights
the best performing parameter sets; blue square indicates the default parameter
set. Barplots show the performance of each parameter set, and red arrow
highlights the best performing parameter set (with the highest performance
score).




After we chose the best performing parameter set for both FSeq and Macs2, we
compared the two peak lists generated by each peak caller to see which peak
caller performs better. We looked at the following parameters:

- overlap with various categories of the annotation + DNaseI peaks
- peak width distribution
- peak height distribution
- overlap between replicates
- signal-to-noise ratio

**Distribution of peaks across various categories of annotation**

From the two boxplots down below (generated from)
we can appreciate that default parameter sets call peaks more peaks in areas
that we do not expect to see ("repressed", "transcribed", "txn"). These
categories disappear for each peak caller when we use the two selected
parameter sets. We can also appreciate that the percentage of peaks falling
within each category is almost identical for both selected parameter sets.


**Peak width distribution**

These density plots demonstrate that chosen parameters for both Macs2 and FSeq call peaks with a more narrow width distribution, and this is what we mainly expect to see in ATAC data. We can also appreciate that `FSeq, chosen parameters` has the most narrow width distribution:




**Peak height distribution**

Density plots down below represent normalized peak intensity -- number of reads
mapped to a certain region annotated as peak and divided by the length of this
region. We can appreciate that when we run either FSeq or Macs2 with chosen
(not default) parameters, we capture a higher fraction of peaks with higher
coverage. This is one of the key metrics, as higher coverage indicates more
evidence and better statistical performance of peak callers. In other words,
deeper sequenced regions are more reliably called as peaks.




**Overlap between replicates**

From this table we can appreciate that FSeq calls many more peaks than Macs2.
However, a lot of them turn to be non-reproducible (13-25% overlap between
replicates in FSeq compared to 51-54% in Macs2). However, when non-reproducible
peaks are removed, we are left with more peaks when using FSeq for peak
calling. We can appreciate, however, that the amount of peaks overlapping with
annotation (annotated regions such as promoters, enhancers, etc -- but not,
e.g., repressed) is higher for Macs2 (75% for the chosen parameter set) than
for FSeq (62% for the chosen parameter set).

|    | Average number of called peaks | Overlap between replicates | Number of overlapping peaks | Peaks mapped "on target", number | Peaks mapped "on target", percent |
| ------------------------ | ------- | ------ | ------ | ------ | ------ |
| FSeq default parameters  | 221,509 | 13.84% | 30,481 |  7,270 | 23.85% |
| FSeq chosen parameters   |  86,044 | 24.00% | 20,625 | 12,768 | 61.91% |
| Macs2 default parameters |  32,928 | 53.26% | 17,456 |  8,784 | 50.32% |
| Macs2 chosen parameters  |  23,383 | 51.66% | 12,053 |  9,010 | 74.75% |


**Signal to noise ratio**

| Parameter set            | Fresh K562 | Frozen K562 |
| ------------------------ | ---------- | ----------- |
| FSeq default parameters  | 3.5        | 1.65        |
| FSeq chosen parameters   | 1.7        | 1.15        |
| Macs2 default parameters | 3.48       | 3.35        |
| Macs2 chosen parameters  | 2.34       | 2.17        |


#### Conclusion

-------------------------------------------------
developed by Irina Pulyakhina irina@well.ox.ac.uk
