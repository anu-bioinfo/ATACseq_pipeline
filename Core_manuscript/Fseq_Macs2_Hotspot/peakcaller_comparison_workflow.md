Comparing the performance of peak callers
------------------------------------------

No research on peak callers and their parameters for ATAC data has currently
been done. We decided to test two widely used peak callers -- Macs2 (initially
designed for ChIP-Seq data) and FSeq (initially designed for DNaseI data). We
ran peak calling using each of the tools and ranging two parameters which are
expected to have a major influence on peak calling:

- length/width/shifting of the statistical model which directly influences the
  average width of peaks to be called (`-l` for FSeq; `--extsize` for Macs2)
- significance threshold which determines how different from a background noise
  the signal should be to be considered as a peak (`-t` for FSeq; `--qvalue`
  for Macs2)

We used data generated from fresh K562 cells, as we consider it gold standard,
least biased (by freezing/fixing) and most accurate, therefore a perfect
candidate for testing peak callers on.

[This paper](http://journals.plos.org/plosone/article/asset?id=10.1371%2Fjournal.pone.0096303.PDF)
was used as a reference point as it performed a similar task for DNaseI data.

#### Experimental design

We had three samples (`bam` files as input for Macs2 and `bed` files as input
for FSeq) of fresh K562 cells, namely `fresh1`, `fresh2`, `fresh3`, which were
technical replicates of the same sample.

We ran
[FSeq](https://raw.githubusercontent.com/jknightlab/ATACseq_pipeline/master/Core_manuscript/Fseq_Macs2_Hotspot/run_fseq.sh)
ranging the two parameters in the following way:

- Paper: 0.001, 0.005, 0.05, 0.1, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 6.
- Us: 0.01, 1, 2, 4, 6, 8, 10, 12, 14, 16 (threshold)
- Us: 100 200 400 600 800 1000 2000 (length)

We ran
[Macs2](https://raw.githubusercontent.com/jknightlab/ATACseq_pipeline/master/Core_manuscript/Fseq_Macs2_Hotspot/run_macs.sh)
ranging the two parameters in the following way:

- Paper: 0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3
- Us: 0.001, 0.005, 0.01, 0.02, 0.03, 0.05, 0.07, 0.09, 0.1, 0.5 (q-value)
- Us: 100 200 400 600 800 1000 2000 (extension)

Code to generate intersections (using Fseq peaks as example):
```
for l in `echo 100 200 400 600 800 1000 2000`
do
    for t in `echo 1.5 2 2.5 3 4 6 8 10 12 14 16`
    do
        fresh1=`find .. | grep "fresh1.filtered.bedpe.fseq.length_$l.tresh_$t\.na"`
        fresh2=`find .. | grep "fresh2.filtered.bedpe.fseq.length_$l.tresh_$t\.na"`
        fresh3=`find .. | grep "fresh3.filtered.bedpe.fseq.length_$l.tresh_$t\.na"`

        bases1=`cat $fresh1 | awk '{sum += $3-$2} END {print sum}'`
        bases2=`cat $fresh2 | awk '{sum += $3-$2} END {print sum}'`
        bases3=`cat $fresh3 | awk '{sum += $3-$2} END {print sum}'`

        overlap=`bedtools intersect -f 0.3 -r -a $fresh1 -b $fresh2 | \
            bedtools intersect -f 0.3 -r -a - -b $fresh3 | \
            bedtools sort -i - | \
            bedtools merge -i - | \
            awk '{sum += $3-$2} END {print sum}'`
        bedtools intersect -f 0.3 -r -a $fresh1 -b $fresh2 | \
            bedtools intersect -f 0.3 -r -a - -b $fresh3 | \
            bedtools sort -i - | \
            bedtools merge -i - > \
            fresh.fseq.l_$l.t_$t.bed

        echo length_$l.thresh_$t Overlap=$overlap Bases1=$bases1 Bases2=$bases2 Bases3=$bases3
    done
    echo
done
```


#### Choice of best parameters per peak caller

Choosing best parameters per peak caller turned out to be very complicated. We
looked at things like sensitivity, specificity, F-Score, distribution of called
peaks across annotated categories (TSS, enhancer regions, repressed regions,
etc). The problem with all those metrics is that when we increase the
width/length parameter, peak callers tend to call wider peaks, often join
narrow adjacent peaks. When we have wider window (2000 bases compared to 100),
we will most probably call more "true" events (annotated peaks), simply because
the covered area is so wide. Therefore we decided to look at a number of
metrics (FDR, sensitivity, specificity, F-Score) and choose the best parameter
set based on the combination of these metrics.

To identify "true annotated peaks", we need a good annotation which contains
only regions that we expect ATAC peaks to map to (such as promoters and
enhancers; but not repressed or transcribed regions). We looked at different
annotations and their combinations:

- Encode K562 regulatory elements annotation generated by Segwey
- Encode K562 regulatory elements annotation generated by ChromM
- Duke K562 DNaseI sites
- overlap of "1_active_promoter", "2_weak_promoter", "4_strong_enhancer",
  "6_weak_enhancer" from ChromM
- overlap of that with DNase
- overlap of "TSS", "Enhancer", "Weak_Enhancer" and "CTCF" from Segwey
- overlap of that with DNase
- overlap of "on target" areas (described above) between ChromM and Segwey
- overlap of "on target" areas (described above) between ChromM, Segwey and
  DNase

We came to the conclusion that Segwey "on target" areas are the best annotation
set. Annotation provided by ChromM contains too wide peaks (kbs wide).
Annotation of DNase peaks contains too narrow peaks (150 bp wide). Overlaps of
the annotations produce very limited, restricted lists of regions which do not
tend to be informative.

We used the intersection of peaks called in 3 fresh ATAC K562 samples (peaks
were called intersected if they had at least 30% overlap reciprocally in all
three samples). We required the overlap of 20% of ATAC peak length with an
annotated peak.

Code to generate intersections of peaks and the overlaps of these
intersections with the annotation:


- on_target="/well/bsgjknight/Irina_analysis/Annotation/segmentation.on_target.bed"
- off_target="/well/bsgjknight/Irina_analysis/Annotation/segmentation.off_target.bed"

```
for i in `ls fresh*bed`
do
    bases=`cat $i | awk '{sum += $3-$2} END {print sum}'`
    on_target=`bedtools intersect -f 0.2 -r \
        -a $i -b /well/bsgjknight/Irina_analysis/Annotation/seg.CTCF_TSS_E_WE.bed | \
        bedtools intersect -u -a - -b $i | \
        bedtools sort -i - | \
        bedtools merge -i - | \
        awk '{sum += $3-$2} END {print sum}'`
    off_target=`bedtools intersect -f 0.2 -r \
        -a $i -b /well/bsgjknight/Irina_analysis/Annotation/segmentation.off_target.bed | \
        bedtools intersect -u -a - -b $i | \
        bedtools sort -i - | \
        bedtools merge -i - | \
        awk '{sum += $3-$2} END {print sum}'`
    on_bases=`cat /well/bsgjknight/Irina_analysis/Annotation/seg.CTCF_TSS_E_WE.bed | \
        awk '{sum += $3-$2} END {print sum}'`
    off_bases=`cat /well/bsgjknight/Irina_analysis/Annotation/segmentation.off_target.bed | \
        awk '{sum += $3-$2} END {print sum}'`
    echo -e "$i\t$bases\t$on_bases\t$off_bases\t$on_target\t$off_target"
done | \
sed s/t_1.b/t_01.b/g | \
sed s/t_1.5.b/t_01.5.b/g | \
sed s/t_2.b/t_02.b/g | \
sed s/t_2.5.b/t_02.5.b/g | \
sed s/t_3.b/t_03.b/g | \
sed s/t_4.b/t_04.b/g | \
sed s/t_6/t_06/g | \
sed s/t_8/t_08/g | \
sed s/l_100.t/l_0100.t/g | \
sed s/l_200.t/l_0200.t/g | \
sed s/l_400.t/l_0400.t/g | \
sed s/l_600.t/l_0600.t/g | \
sed s/l_800.t/l_0800.t/g | \
sort -n -k 1
```


### Results

#### Choosing the best parameters for FSeq

Higher F-Score for length values 800, 1000 and 2000 (default 600 is not in this
list, indicating that the default settings might not be the ones showing the
best performance). The highest F-Score values were calculated for the
combinations of length=800 and threshold=2, length=2000 and threshold=4 and
length=1000 and threshold=2. We looked at some more stats for those parameter
combinations.


| Parameters               | F-Score | Overlap between replicates | %bases mapped to annotation | On_target/(On_target+Off_target) |
| ------------------------ | ------- | -------------------------- | --- | --- |
| length=800, threshold=2  | 0.527   | 15.33%                     | 70% | 97% |
| length=2000, threshold=4 | 0.529   | 46.8%                      | 69% | 97% |
| length=1000, threshold=2 | 0.533   | 17.2%                      | 66% | 96% |

Based on reasonably high F-Score, the highest specificity and the highet
percentage of bases mapped on target we chose the parameter set of
**length=800, threshold=2**.

It is worth mentioning that we replicated the results from the paper which
showed the same behaviour of F-Score with changing threshold values and
suggested to use a threshold value between 2 and 3 for DNaseI data.


#### Choosing the best parameters for FSeq

Higher Macs2 were observed for the extension values of 600 and 800 (default 200
is not in this list, indicating that the default settings might not be the ones
showing the best performance). The highest F-Score values were calculated for
the combinations of extension=800 and qvalue=0.05 and length=600 and
qvalue=0.07. Similarly to FSeq, here we looked at some more stats for those
parameter combinations.


| Parameters                 | F-Score | Overlap between replicates | %bases mapped to annotation | On_target/(On_target+Off_target) |
| -------------------------- | ------- | -------------------------- | --- | ----- |
| extension=800, qvalue=0.05 | 0.504   | 61.68%                     | 63% | 96.5% |
| extension=600, qvalue=0.07 | 0.525   | 46.8%                      | 69% | 97%   |

Based on reasonably high F-Score, the highest specificity and the highet
percentage of bases mapped on target we chose the parameter set of
**extension=600, qvalue=0.07**.

Again, in terms of qvalue we got very close to the results from the paper. They
suggest to use qval=0.05 for DNaseI data.


Based on the observations described above we chose the following parameters as
optimal:

| Peak caller | Default parameters | Chosen parameters   |
| ----------- | ------------------ | ------------------- |
| FSeq        | l=600, t=4         | **l=800, t=2**     |
| Macs2       | ext=200, q=0.05    | **ext=600, q=0.07** |


Here is what F-Score looks like:

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/Fresh.Fseq_Macs2.Fscore.png)


F-Score, sensitivity and specificity, %bases mapped on target -- all that
information can be found:

- for FSeq [here](https://raw.githubusercontent.com/jknightlab/ATACseq_pipeline/master/Core_manuscript/Fseq_Macs2_Hotspot/fseq.bases_fscore.txt)
- for Macs2 [here](https://raw.githubusercontent.com/jknightlab/ATACseq_pipeline/master/Core_manuscript/Fseq_Macs2_Hotspot/macs.bases_fscore.txt)





# Old


#### Choosing the best peak caller

After we chose the best performing parameter set for both FSeq and Macs2, we
compared the two peak lists generated by each peak caller to see which peak
caller performs better. We looked at the following parameters:

- overlap with various categories of the annotation
- overlap with DNaseI peaks
- peak width distribution
- peak height distribution
- overlap between replicates
- signal-to-noise ratio


**Distribution of peaks across various categories of annotation**

K562 segmentation track of annotated regulatory elements used by ENCODE was
taken from
[here](http://ucscbrowser.genap.ca/cgi-bin/hgTrackUi?hgsid=275287_Q3Wf4yyipacgB10HhqrM1BhHe10F&c=chr7&g=hub_1_genomeSegmentation).

This is the legend interpretation

- Distal CTCF/Candidate Insulator (CTCF)
- Candidate strong enhancer (E)
- Candidate weak enhancer (WE)
- Repressed (R)
- Promoter flanking (PF)
- Transcribed (T)
- TSS (TSS)

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/peak_distribution_across_annotation.png)

From the two boxplots above (generated from
[this data](https://raw.githubusercontent.com/jknightlab/ATACseq_pipeline/master/Core_manuscript/Fseq_Macs2_Hotspot/peak_distribution_over_annotation_categories.txt)
)
we can appreciate that default parameter sets call peaks more peaks in areas
that we do not expect to see ("repressed", "transcribed", "promoter flanking").
These categories disappear for each peak caller when we use the two selected
parameter sets. We can also appreciate that the percentage of peaks falling
within each category is almost identical for both selected parameter sets.

On the bottom two plots you can see what the distribution of peaks look like
when we group all "off target" categories (repressed and transcribed regions,
promoter flanking) and "on target" categories (enhancer, weak enhancer, TSS,
[CTCF](https://en.wikipedia.org/wiki/CTCF)).


**Overlap with DNaseI peaks**

- Fseq chosen parameters: called 10,211 peaks and 5,660,092 bases.
- Fseq default parameters: called 30,481 peaks and 16,258,123 bases.
- Macs2 chosen parameters: called 12,053 peaks and 3,705,520 bases.
- Macs2 default parameters: called 17,456 peaks and 8,674,924 bases.

From this table we can appreciate that default parameters call more peaks than
chosen parameters for both FSeq and Macs2.  However, % overlap with DNaseI
peaks is always, at each cutoff higher for chosen parameter values.  When
comparing chosen parameters of FSeq to chosen parameters of Macs2, we can
appreciate that Macs2 always produces higher overlaps with DNaseI peaks both in
number and in % of both peaks and bases.


|  |overlap peaks | overlap bases | % overlap peaks | % overlap bases |
| ------------------------ | ------ | --------- | ----- | ----- |
| 1 bp overlap required    |        |           |       |       |
| Fseq chosen parameters   | 10,111 | 2,129,143 | 99.02 | 37.62 |
| Fseq default parameters  | 27,214 | 5,492,672 | 89.29 | 33.78 |
| Macs2 chosen parameters  | 11,706 | 1,809,307 | 97.12 | 48.83 |
| Macs2 default parameters | 16,798 | 3,265,043 | 96.23 | 37.64 |
|                          |        |           |       |       |
| 20% overlap required     |        |           |       |       |
| Fseq chosen parameters   | 7,633  | 3,146,105 | 74.75 | 55.58 |
| Fseq default parameters  | 19,519 | 7,221,824 | 64.04 | 44.42 |
| Macs2 chosen parameters  | 10,785 | 2,903,186 | 89.48 | 78.35 |
| Macs2 default parameters | 13,087 | 4,992,763 | 74.97 | 57.55 |
|                          |        |           |       |       |
| 30% overlap required     |        |           |       |       |
| Fseq chosen parameters   | 4,979  | 1,567,181 | 48.76 | 27.69 |
| Fseq default parameters  | 13,826 | 3,952,452 | 45.36 | 24.31 |
| Macs2 chosen parameters  | 9,246  | 2,043,185 | 76.71 | 55.14 |
| Macs2 default parameters | 9,193  | 2,807,125 | 52.66 | 32.36 |
|                          |        |           |       |       |
| 40% overlap required     |        |           |       |       |
| Fseq chosen parameters   | 3,074  | 773,220   | 30.1  | 13.66 |
| Fseq default parameters  | 9,359  | 2,183,119 | 30.7  | 13.43 |
| Macs2 chosen parameters  | 7,601  | 1,406,488 | 63.06 | 37.97 |
| Macs2 default parameters | 5,740  | 1,438,146 | 32.88 | 16.58 |



**Peak width distribution**

These density plots demonstrate that chosen parameters for both Macs2 and FSeq
call peaks with a different width distribution -- narrower for Macs2 and wider
for FSeq.

| Mode of peak width | Default parameters | Chosen parameters   |
| ------------------ | ------------------ | ------------------- |
| FSeq               | 210 bp    | **380 bp**   |
| Macs2              | 210 bp    | **180 bp**   |
|

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/peak_width_distribution.png)


**Peak height distribution**

Density plots down below represent normalized peak intensity -- number of reads
mapped to a certain region annotated as peak and divided by the length of this
region. This is one of the key metrics, as higher coverage indicates more
evidence and better statistical performance of peak callers. In other words,
deeper sequenced regions are more reliably called as peaks.

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/peak_intensity_distribution.png)


We can appreciate that when we run either FSeq or Macs2 with chosen (not
default) parameters, we capture a higher fraction of peaks with higher
coverage. However, FSeq peaks called with chosen parameters have slightly lower
average intensity compared to the peaks called with Macs2 chosen parameters.
This might be happening due to the width of peaks and that the two peak callers
have very different models, Macs2 was run with low length value (100, 200),
while FSeq was run with my larger length values (600, 800). We did normalize
for the peak width, however, peak nature implies that it has a spike in the
middle and has high coverage over that spike and less coverage around it. So
when the area around it is wide enough, we might be diluting the signal.  To
account for that, we created another peak intensity distribution plot, but now
we took the middle position of the peak and 50 bp upstread and downstream of it
as the region of interest. We can see that indeed, average intensity of peaks
is very similar for Macs2 and Fseq now; in fact, the mode of peak intensity
distribution is slihtly higher for FSeq peaks called with chosen parameters.

![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/peak_intensity_distribution_100bp.png)


**Overlap between replicates**

We required 50% overlap of peak width reciprocally. From this table we can
appreciate that FSeq calls many more peaks than Macs2 with default options.
With chosen options it calls less peaks than Macs2 with chosen options,
nevertheless the fraction of peaks overlapping between replicates is higher for
FSeq chosen parameters (67% agains 46%).  When non-reproducible peaks are
removed, we are left with almost the same amount of overlapping peaks for FSeq
and Macs2. In other words, whe using FSeq we get higher % and the same number
of overlapping peaks.

|    | Average number of called peaks | Overlap between replicates | Number of overlapping peaks | 
| ------------------------ | ------- | ------- | ------ | 
| FSeq default parameters  | 221,509 |  13.62% | 30,171 |
| FSeq chosen parameters   |  15,354 |  66.8%  | 10,256 |
| Macs2 default parameters |  32,928 |  50.53% | 16,638 |
| Macs2 chosen parameters  |  23,383 |  46.54% | 10,882 |


**Signal to noise ratio**

We can see that signal to noise ratio is not very much influenced by different
parameters. Even more so -- it drops for chosen macs2 parameters. This is most
probably caused by the fact that we are calling more peaks with default
parameters, which means there are areas which do contain some coverage. When we
call less peaks, we restrict the area of peaks (and therefore count less
reads), however, our background now includes those areas which used to be peaks
and have some coverage. Therefore we normalized signal-to-noise ratio by the
number of bases in called peaks. We did the same normalization of S2N for the
number of called peaks, it gave very similar results. However, since we are
already using bases for other metrics (Fscore, Sensitivity, etc), we decided to
use base pairs here as well.

Looking at the normalized S2N, we can appreciate that S2N increased greatly for
chosen parameters compared to the default parameters and is slightly higher for
Macs2 than for FSeq.

| Parameter set            | Fresh K562 | S2N / #bp |
| ------------------------ | ---------- | --------- |
| FSeq default parameters  | 3.5        | 2.15      | 
| FSeq chosen parameters   | 3.3        | 5.8       |
| Macs2 default parameters | 3.48       | 4.01      |
| Macs2 chosen parameters  | 2.34       | 6.31      |


#### Illustrations

[This](https://genome-euro.ucsc.edu/cgi-bin/hgTracks?hgS_doOtherUser=submit&hgS_otherUserName=pulyakhina&hgS_otherUserSessionName=K562_fresh_FSeq_Macs2_chosen_parameters)
session was used to create the figures.

|             |            |
| ----------- | ---------- |
| ![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/UCSC_examples/one.png) | ![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/UCSC_examples/two.png)  |
| ![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/UCSC_examples/three.png) | ![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/UCSC_examples/four.png)  |
| ![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/UCSC_examples/five.png) | ![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/UCSC_examples/six.png)  |
| ![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/UCSC_examples/seven.png) | ![alt text](https://github.com/jknightlab/ATACseq_pipeline/blob/master/Core_manuscript/Fseq_Macs2_Hotspot/UCSC_examples/eight.png)  |


#### Conclusion

|                                          | FSeq      | Macs2     |
| ---------------------------------------- | --------- | --------- |
| overlap with "on target" annotation, %   | 66%       | 33%       |
| overlap with "off target" annotation, %  | 0.08%     | 0.02%     |
| overlap with "on target" annotation, bp  | 6,769     | 3,960     |
| overlap with "off target" annotation, pk | 9         | 3         |
| overlap with DNaseI peaks, bp            | 3,146,105 | 2,903,186 |
| overlap with DNaseI peaks, %             | 75%       | 89%       |
| peak width distribution                  | 380 bp    | 180 bp    |
| peak height distribution                 | higher    | lower     |
| overlap between replicates               | 67%       | 47%       |
| signal-to-noise ratio                    | 5.8       | 6.3       |

FSeq peaks are more enriched for the "on target" K562 regulatory elements; in
base pairs, they are more enriched for DNaseI peaks (but not in the % of
peaks). The average intensity of FSeq peaks is slightly higher and the overlap
between the replicates is much higher.

Macs2 peaks have a higher % overlap with DNaseI peaks, slightly higher
signal-to-noise ratio and narrower peaks.

Most importantly, when looking at FSeq and Macs2 peaks by eye, FSeq peaks look
more realistic.

Based on these observations we made a decision to use the following peak caller
to analyze our data further on: **FSeq, length 800, threshold 14**.

-------------------------------------------------
developed by Irina Pulyakhina irina@well.ox.ac.uk
